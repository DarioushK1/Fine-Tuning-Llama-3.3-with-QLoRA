{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.03215434083601286,
  "eval_steps": 500,
  "global_step": 80,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00040192926045016077,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "loss": 2.0227,
      "step": 1
    },
    {
      "epoch": 0.0008038585209003215,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "loss": 1.7266,
      "step": 2
    },
    {
      "epoch": 0.0012057877813504824,
      "grad_norm": 1.2490816116333008,
      "learning_rate": 5e-05,
      "loss": 1.8064,
      "step": 3
    },
    {
      "epoch": 0.001607717041800643,
      "grad_norm": 1.4044560194015503,
      "learning_rate": 0.0001,
      "loss": 2.017,
      "step": 4
    },
    {
      "epoch": 0.0020096463022508037,
      "grad_norm": NaN,
      "learning_rate": 0.0001,
      "loss": 1.8566,
      "step": 5
    },
    {
      "epoch": 0.002411575562700965,
      "grad_norm": 2.1902880668640137,
      "learning_rate": 0.00015000000000000001,
      "loss": 2.1493,
      "step": 6
    },
    {
      "epoch": 0.0028135048231511255,
      "grad_norm": 1.7170352935791016,
      "learning_rate": 0.0002,
      "loss": 1.894,
      "step": 7
    },
    {
      "epoch": 0.003215434083601286,
      "grad_norm": 1.3606032133102417,
      "learning_rate": 0.0001999145758387301,
      "loss": 1.9248,
      "step": 8
    },
    {
      "epoch": 0.003617363344051447,
      "grad_norm": 1.0304652452468872,
      "learning_rate": 0.000199658449300667,
      "loss": 1.5772,
      "step": 9
    },
    {
      "epoch": 0.0040192926045016075,
      "grad_norm": 1.4139204025268555,
      "learning_rate": 0.0001992320579737045,
      "loss": 1.3739,
      "step": 10
    },
    {
      "epoch": 0.0044212218649517685,
      "grad_norm": 1.190042495727539,
      "learning_rate": 0.00019863613034027224,
      "loss": 1.3565,
      "step": 11
    },
    {
      "epoch": 0.00482315112540193,
      "grad_norm": 0.8725051879882812,
      "learning_rate": 0.00019787168453273544,
      "loss": 1.1792,
      "step": 12
    },
    {
      "epoch": 0.00522508038585209,
      "grad_norm": 0.9595947265625,
      "learning_rate": 0.00019694002659393305,
      "loss": 1.0612,
      "step": 13
    },
    {
      "epoch": 0.005627009646302251,
      "grad_norm": 0.971451461315155,
      "learning_rate": 0.0001958427482458253,
      "loss": 0.7344,
      "step": 14
    },
    {
      "epoch": 0.006028938906752411,
      "grad_norm": 1.3620301485061646,
      "learning_rate": 0.00019458172417006347,
      "loss": 0.7969,
      "step": 15
    },
    {
      "epoch": 0.006430868167202572,
      "grad_norm": 1.1333606243133545,
      "learning_rate": 0.0001931591088051279,
      "loss": 0.6828,
      "step": 16
    },
    {
      "epoch": 0.006832797427652733,
      "grad_norm": 1.0729540586471558,
      "learning_rate": 0.00019157733266550575,
      "loss": 0.6102,
      "step": 17
    },
    {
      "epoch": 0.007234726688102894,
      "grad_norm": 0.8417683243751526,
      "learning_rate": 0.0001898390981891979,
      "loss": 0.6686,
      "step": 18
    },
    {
      "epoch": 0.007636655948553055,
      "grad_norm": 0.914903998374939,
      "learning_rate": 0.0001879473751206489,
      "loss": 0.6688,
      "step": 19
    },
    {
      "epoch": 0.008038585209003215,
      "grad_norm": 0.8714591264724731,
      "learning_rate": 0.00018590539543698854,
      "loss": 0.6667,
      "step": 20
    },
    {
      "epoch": 0.008440514469453377,
      "grad_norm": 0.91131591796875,
      "learning_rate": 0.00018371664782625287,
      "loss": 0.6903,
      "step": 21
    },
    {
      "epoch": 0.008842443729903537,
      "grad_norm": 0.8275606632232666,
      "learning_rate": 0.0001813848717270195,
      "loss": 0.5528,
      "step": 22
    },
    {
      "epoch": 0.009244372990353697,
      "grad_norm": 1.2619050741195679,
      "learning_rate": 0.00017891405093963938,
      "loss": 0.5622,
      "step": 23
    },
    {
      "epoch": 0.00964630225080386,
      "grad_norm": 0.772383987903595,
      "learning_rate": 0.00017630840681998066,
      "loss": 0.6186,
      "step": 24
    },
    {
      "epoch": 0.01004823151125402,
      "grad_norm": 0.6950934529304504,
      "learning_rate": 0.00017357239106731317,
      "loss": 0.6089,
      "step": 25
    },
    {
      "epoch": 0.01045016077170418,
      "grad_norm": 0.6886937022209167,
      "learning_rate": 0.00017071067811865476,
      "loss": 0.5235,
      "step": 26
    },
    {
      "epoch": 0.010852090032154342,
      "grad_norm": 0.7953264117240906,
      "learning_rate": 0.00016772815716257412,
      "loss": 0.6254,
      "step": 27
    },
    {
      "epoch": 0.011254019292604502,
      "grad_norm": 0.6568872928619385,
      "learning_rate": 0.00016462992378609407,
      "loss": 0.5512,
      "step": 28
    },
    {
      "epoch": 0.011655948553054662,
      "grad_norm": 0.6704553961753845,
      "learning_rate": 0.0001614212712689668,
      "loss": 0.5254,
      "step": 29
    },
    {
      "epoch": 0.012057877813504822,
      "grad_norm": 0.7662261724472046,
      "learning_rate": 0.00015810768154019385,
      "loss": 0.6674,
      "step": 30
    },
    {
      "epoch": 0.012459807073954984,
      "grad_norm": 0.7390751838684082,
      "learning_rate": 0.00015469481581224272,
      "loss": 0.5591,
      "step": 31
    },
    {
      "epoch": 0.012861736334405145,
      "grad_norm": 0.8637803196907043,
      "learning_rate": 0.00015118850490896012,
      "loss": 0.5621,
      "step": 32
    },
    {
      "epoch": 0.013263665594855305,
      "grad_norm": 0.5936192274093628,
      "learning_rate": 0.00014759473930370736,
      "loss": 0.4385,
      "step": 33
    },
    {
      "epoch": 0.013665594855305467,
      "grad_norm": 1.077576994895935,
      "learning_rate": 0.00014391965888473703,
      "loss": 0.5557,
      "step": 34
    },
    {
      "epoch": 0.014067524115755627,
      "grad_norm": 0.6192079186439514,
      "learning_rate": 0.00014016954246529696,
      "loss": 0.4903,
      "step": 35
    },
    {
      "epoch": 0.014469453376205787,
      "grad_norm": 0.7868853211402893,
      "learning_rate": 0.00013635079705638298,
      "loss": 0.6486,
      "step": 36
    },
    {
      "epoch": 0.01487138263665595,
      "grad_norm": 0.6467148065567017,
      "learning_rate": 0.00013246994692046836,
      "loss": 0.5083,
      "step": 37
    },
    {
      "epoch": 0.01527331189710611,
      "grad_norm": 0.5976142883300781,
      "learning_rate": 0.00012853362242491053,
      "loss": 0.516,
      "step": 38
    },
    {
      "epoch": 0.01567524115755627,
      "grad_norm": 0.6730998158454895,
      "learning_rate": 0.00012454854871407994,
      "loss": 0.5761,
      "step": 39
    },
    {
      "epoch": 0.01607717041800643,
      "grad_norm": 0.6613635420799255,
      "learning_rate": 0.00012052153421956342,
      "loss": 0.5725,
      "step": 40
    },
    {
      "epoch": 0.01647909967845659,
      "grad_norm": 0.9118778705596924,
      "learning_rate": 0.00011645945902807341,
      "loss": 0.543,
      "step": 41
    },
    {
      "epoch": 0.016881028938906754,
      "grad_norm": 0.6681584119796753,
      "learning_rate": 0.00011236926312693479,
      "loss": 0.5108,
      "step": 42
    },
    {
      "epoch": 0.017282958199356914,
      "grad_norm": 0.6865659356117249,
      "learning_rate": 0.00010825793454723325,
      "loss": 0.5565,
      "step": 43
    },
    {
      "epoch": 0.017684887459807074,
      "grad_norm": 0.6291083097457886,
      "learning_rate": 0.00010413249742488131,
      "loss": 0.5289,
      "step": 44
    },
    {
      "epoch": 0.018086816720257234,
      "grad_norm": 0.6358121633529663,
      "learning_rate": 0.0001,
      "loss": 0.4413,
      "step": 45
    },
    {
      "epoch": 0.018488745980707395,
      "grad_norm": 0.7347045540809631,
      "learning_rate": 9.586750257511867e-05,
      "loss": 0.5522,
      "step": 46
    },
    {
      "epoch": 0.018890675241157555,
      "grad_norm": 1.130030632019043,
      "learning_rate": 9.174206545276677e-05,
      "loss": 0.476,
      "step": 47
    },
    {
      "epoch": 0.01929260450160772,
      "grad_norm": 0.48275092244148254,
      "learning_rate": 8.763073687306524e-05,
      "loss": 0.3898,
      "step": 48
    },
    {
      "epoch": 0.01969453376205788,
      "grad_norm": 0.5733797550201416,
      "learning_rate": 8.35405409719266e-05,
      "loss": 0.4486,
      "step": 49
    },
    {
      "epoch": 0.02009646302250804,
      "grad_norm": 0.759628415107727,
      "learning_rate": 7.947846578043659e-05,
      "loss": 0.4224,
      "step": 50
    },
    {
      "epoch": 0.0204983922829582,
      "grad_norm": 1.1092724800109863,
      "learning_rate": 7.54514512859201e-05,
      "loss": 0.5683,
      "step": 51
    },
    {
      "epoch": 0.02090032154340836,
      "grad_norm": 0.9114463329315186,
      "learning_rate": 7.146637757508949e-05,
      "loss": 0.5322,
      "step": 52
    },
    {
      "epoch": 0.02130225080385852,
      "grad_norm": 0.5660496354103088,
      "learning_rate": 6.753005307953167e-05,
      "loss": 0.4673,
      "step": 53
    },
    {
      "epoch": 0.021704180064308683,
      "grad_norm": 0.6148203015327454,
      "learning_rate": 6.3649202943617e-05,
      "loss": 0.5701,
      "step": 54
    },
    {
      "epoch": 0.022106109324758844,
      "grad_norm": 0.638203501701355,
      "learning_rate": 5.983045753470308e-05,
      "loss": 0.4082,
      "step": 55
    },
    {
      "epoch": 0.022508038585209004,
      "grad_norm": 0.6575920581817627,
      "learning_rate": 5.608034111526298e-05,
      "loss": 0.4815,
      "step": 56
    },
    {
      "epoch": 0.022909967845659164,
      "grad_norm": 0.5102622509002686,
      "learning_rate": 5.240526069629265e-05,
      "loss": 0.3568,
      "step": 57
    },
    {
      "epoch": 0.023311897106109324,
      "grad_norm": 0.596947968006134,
      "learning_rate": 4.8811495091039926e-05,
      "loss": 0.4679,
      "step": 58
    },
    {
      "epoch": 0.023713826366559485,
      "grad_norm": 0.787506639957428,
      "learning_rate": 4.530518418775733e-05,
      "loss": 0.5448,
      "step": 59
    },
    {
      "epoch": 0.024115755627009645,
      "grad_norm": 0.7829527854919434,
      "learning_rate": 4.189231845980618e-05,
      "loss": 0.5853,
      "step": 60
    },
    {
      "epoch": 0.02451768488745981,
      "grad_norm": 0.626848578453064,
      "learning_rate": 3.857872873103322e-05,
      "loss": 0.4896,
      "step": 61
    },
    {
      "epoch": 0.02491961414790997,
      "grad_norm": 0.5882775783538818,
      "learning_rate": 3.53700762139059e-05,
      "loss": 0.4057,
      "step": 62
    },
    {
      "epoch": 0.02532154340836013,
      "grad_norm": 0.5657187104225159,
      "learning_rate": 3.227184283742591e-05,
      "loss": 0.4641,
      "step": 63
    },
    {
      "epoch": 0.02572347266881029,
      "grad_norm": 0.7878170013427734,
      "learning_rate": 2.9289321881345254e-05,
      "loss": 0.4773,
      "step": 64
    },
    {
      "epoch": 0.02612540192926045,
      "grad_norm": 0.5827446579933167,
      "learning_rate": 2.6427608932686843e-05,
      "loss": 0.4361,
      "step": 65
    },
    {
      "epoch": 0.02652733118971061,
      "grad_norm": 0.6274906396865845,
      "learning_rate": 2.3691593180019366e-05,
      "loss": 0.5275,
      "step": 66
    },
    {
      "epoch": 0.026929260450160773,
      "grad_norm": 1.992514729499817,
      "learning_rate": 2.1085949060360654e-05,
      "loss": 0.538,
      "step": 67
    },
    {
      "epoch": 0.027331189710610933,
      "grad_norm": 0.7089669108390808,
      "learning_rate": 1.861512827298051e-05,
      "loss": 0.5673,
      "step": 68
    },
    {
      "epoch": 0.027733118971061094,
      "grad_norm": 0.6495252847671509,
      "learning_rate": 1.6283352173747145e-05,
      "loss": 0.6016,
      "step": 69
    },
    {
      "epoch": 0.028135048231511254,
      "grad_norm": 0.6199148893356323,
      "learning_rate": 1.4094604563011472e-05,
      "loss": 0.4158,
      "step": 70
    },
    {
      "epoch": 0.028536977491961414,
      "grad_norm": 0.6926420331001282,
      "learning_rate": 1.2052624879351104e-05,
      "loss": 0.5791,
      "step": 71
    },
    {
      "epoch": 0.028938906752411574,
      "grad_norm": 0.6196467876434326,
      "learning_rate": 1.0160901810802115e-05,
      "loss": 0.5402,
      "step": 72
    },
    {
      "epoch": 0.029340836012861738,
      "grad_norm": 0.6080542802810669,
      "learning_rate": 8.422667334494249e-06,
      "loss": 0.5251,
      "step": 73
    },
    {
      "epoch": 0.0297427652733119,
      "grad_norm": 0.7029280066490173,
      "learning_rate": 6.840891194872112e-06,
      "loss": 0.5053,
      "step": 74
    },
    {
      "epoch": 0.03014469453376206,
      "grad_norm": 0.5958077907562256,
      "learning_rate": 5.418275829936537e-06,
      "loss": 0.3999,
      "step": 75
    },
    {
      "epoch": 0.03054662379421222,
      "grad_norm": 0.6109673976898193,
      "learning_rate": 4.1572517541747294e-06,
      "loss": 0.452,
      "step": 76
    },
    {
      "epoch": 0.03094855305466238,
      "grad_norm": 0.5211323499679565,
      "learning_rate": 3.059973406066963e-06,
      "loss": 0.4126,
      "step": 77
    },
    {
      "epoch": 0.03135048231511254,
      "grad_norm": 0.7180851697921753,
      "learning_rate": 2.128315467264552e-06,
      "loss": 0.4925,
      "step": 78
    },
    {
      "epoch": 0.0317524115755627,
      "grad_norm": 0.622929036617279,
      "learning_rate": 1.3638696597277679e-06,
      "loss": 0.3537,
      "step": 79
    },
    {
      "epoch": 0.03215434083601286,
      "grad_norm": 0.627526044845581,
      "learning_rate": 7.679420262954984e-07,
      "loss": 0.4297,
      "step": 80
    }
  ],
  "logging_steps": 1,
  "max_steps": 80,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.7364751692529664e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
